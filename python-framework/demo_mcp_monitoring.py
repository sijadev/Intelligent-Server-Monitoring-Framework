#!/usr/bin/env python3
"""
Demo der Intelligent MCP Code Monitoring FunktionalitÃ¤t
Zeigt das vollstÃ¤ndige Workflow: Monitor â†’ Detect â†’ Fix â†’ Validate
"""

import asyncio
import json
import logging
import time
from pathlib import Path
from datetime import datetime

# Setup Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Import unsere Systeme
from intelligent_mcp_code_monitor import IntelligentMCPCodeMonitor
from real_ai_learning_system import initialize_real_ai_system, ML_AVAILABLE

async def create_demo_files():
    """Erstelle Demo-Dateien mit typischen Code-Fehlern"""
    demo_dir = Path("./demo_mcp_code")
    demo_dir.mkdir(exist_ok=True)
    
    # JavaScript-Datei mit typischen Fehlern
    js_code = '''
// Demo MCP Server Code mit Fehlern
const express = require('express');
const app = express();

function calculateTotal(items) {
    let total = 0;
    for (let item of items) {
        // Fehler: Null-Check fehlt
        total += item.price;
    }
    return total
} // Fehler: Fehlender Semicolon

function processData(data) {
    // Fehler: Typo - sollte "length" sein
    return data.lenght;
}

// Undefined function call
function main() {
    const items = [null, {price: 10}, {price: 20}];
    const total = calculateSum(items); // Fehler: calculateSum existiert nicht
    console.log('Total:', total);
}

app.get('/health', (req, res) => {
    res.json({status: 'ok'});
});

app.listen(3000, () => {
    console.log('MCP Server running on port 3000');
});
'''
    
    with open(demo_dir / "mcp_server.js", "w") as f:
        f.write(js_code)
    
    # Python-Datei mit Fehlern
    py_code = '''
# Demo MCP Server Python Code mit Fehlern
from flask import Flask, jsonify
import json

app = Flask(__name__)

def calculate_average(numbers):
    # Fehler: Division durch Null mÃ¶glich
    return sum(numbers) / len(numbers)

def process_user_data(user_data):
    # Fehler: Null-Check fehlt
    return user_data.get('name').upper()

@app.route('/api/data')
def get_data():
    try:
        # Fehler: undefined_variable
        return jsonify({'result': undefined_result})
    except Exception as e:
        return jsonify({'error': str(e)})

@app.route('/health')
def health():
    return jsonify({'status': 'healthy'})

if __name__ == '__main__':
    app.run(debug=True, port=5000)
'''
    
    with open(demo_dir / "mcp_server.py", "w") as f:
        f.write(py_code)
    
    print(f"âœ… Demo-Dateien erstellt in: {demo_dir}")
    return demo_dir

async def simulate_mcp_server_logs():
    """Simuliere MCP Server Logs mit Fehlern"""
    logs = [
        "2024-08-04 19:30:00 ERROR TypeError: Cannot read property 'price' of null at calculateTotal (mcp_server.js:8:15)",
        "2024-08-04 19:30:15 ERROR ReferenceError: lenght is not defined at processData (mcp_server.js:15:17)",
        "2024-08-04 19:30:30 ERROR ReferenceError: calculateSum is not defined at main (mcp_server.js:21:17)",
        "2024-08-04 19:30:45 ERROR NameError: name 'undefined_result' is not defined at get_data (mcp_server.py:15:44)",
        "2024-08-04 19:31:00 ERROR AttributeError: 'NoneType' object has no attribute 'upper' at process_user_data (mcp_server.py:10:29)"
    ]
    
    return logs

async def run_comprehensive_demo():
    """FÃ¼hre eine umfassende Demo des MCP Monitoring Systems aus"""
    print("ğŸ¬ INTELLIGENT MCP CODE MONITORING DEMO")
    print("=" * 60)
    
    # 1. Setup Demo Environment
    print("\nğŸ“ Setting up demo environment...")
    demo_dir = await create_demo_files()
    
    # 2. Initialize AI System (wenn verfÃ¼gbar)
    print(f"\nğŸ§  AI System Setup (ML_AVAILABLE: {ML_AVAILABLE})...")
    ai_system = None
    if ML_AVAILABLE:
        try:
            ai_config = {
                'ai_model_dir': './ai_models',
                'learning_enabled': True
            }
            ai_system = await initialize_real_ai_system(ai_config)
            print("âœ… AI Learning System initialized")
        except Exception as e:
            print(f"âš ï¸ AI System initialization failed: {e}")
    else:
        print("â„¹ï¸ Using fallback predictions (install ML libraries for full AI capabilities)")
    
    # 3. Initialize MCP Monitor
    print("\nğŸš€ Initializing Intelligent MCP Monitor...")
    config = {
        'scan_interval': 5,  # 5 Sekunden fÃ¼r Demo
        'auto_fix_enabled': True,
        'min_confidence_threshold': 0.7,
        'source_directories': [str(demo_dir), './server'],
        'scan_ports': [3000, 5000, 8000, 8080],
        'scan_hosts': ['localhost'],
        'discovery_methods': ['process_scan', 'port_scan']
    }
    
    monitor = IntelligentMCPCodeMonitor(config)
    if not await monitor.initialize():
        print("âŒ Failed to initialize monitor")
        return
    
    print("âœ… Monitor initialized successfully")
    print(f"   - Monitoring {len(config['source_directories'])} directories")
    print(f"   - Auto-fix enabled: {config['auto_fix_enabled']}")
    print(f"   - Confidence threshold: {config['min_confidence_threshold']}")
    
    # 4. Simulate MCP Server Discovery
    print("\nğŸ” Phase 1: MCP Server Discovery")
    print("-" * 40)
    
    # Simuliere gefundene Server
    print("   Scanning for MCP servers...")
    await asyncio.sleep(1)  # Simuliere Scan-Zeit
    
    simulated_servers = [
        {"name": "Demo MCP Server (JS)", "host": "localhost", "port": 3000, "status": "running"},
        {"name": "Demo MCP Server (Python)", "host": "localhost", "port": 5000, "status": "running"}
    ]
    
    for server in simulated_servers:
        print(f"   ğŸ“¡ Found: {server['name']} ({server['host']}:{server['port']}) - {server['status']}")
    
    # 5. Simulate Log Analysis and Issue Detection
    print("\nğŸ•µï¸ Phase 2: Log Analysis & Issue Detection")
    print("-" * 40)
    
    logs = await simulate_mcp_server_logs()
    detected_issues = []
    
    print("   Analyzing server logs...")
    for i, log in enumerate(logs):
        print(f"   ğŸ“‹ Log {i+1}: {log}")
        
        # Simuliere Code-Issue-Detection
        if "TypeError" in log and "null" in log:
            issue = {
                "type": "null_pointer",
                "severity": "HIGH",
                "file": "mcp_server.js",
                "line": 8,
                "description": "Null pointer access in calculateTotal function",
                "confidence": 0.9
            }
            detected_issues.append(issue)
        elif "lenght" in log:
            issue = {
                "type": "undefined_function",
                "severity": "MEDIUM", 
                "file": "mcp_server.js",
                "line": 15,
                "description": "Typo: 'lenght' should be 'length'",
                "confidence": 0.95
            }
            detected_issues.append(issue)
        elif "calculateSum" in log:
            issue = {
                "type": "undefined_function",
                "severity": "HIGH",
                "file": "mcp_server.js", 
                "line": 21,
                "description": "Function 'calculateSum' not defined, should be 'calculateTotal'",
                "confidence": 0.85
            }
            detected_issues.append(issue)
    
    print(f"\n   ğŸš¨ Total Issues Detected: {len(detected_issues)}")
    for i, issue in enumerate(detected_issues):
        print(f"   {i+1}. {issue['type']} in {issue['file']}:{issue['line']} "
              f"(confidence: {issue['confidence']:.1%})")
    
    # 6. ML Predictions and Auto-Fix
    print("\nğŸ§  Phase 3: ML Predictions & Auto-Fix")
    print("-" * 40)
    
    fixes_attempted = 0
    fixes_successful = 0
    
    for issue in detected_issues:
        if issue['confidence'] >= config['min_confidence_threshold']:
            fixes_attempted += 1
            print(f"\n   ğŸ”§ Attempting fix for {issue['type']}...")
            print(f"      File: {issue['file']}:{issue['line']}")
            print(f"      Issue: {issue['description']}")
            print(f"      Confidence: {issue['confidence']:.1%}")
            
            # Simuliere ML-Vorhersage
            if ai_system:
                print("      ğŸ§  ML Prediction: Using trained models...")
                success_probability = issue['confidence'] * 0.9  # Simuliere AI-Vorhersage
            else:
                print("      ğŸ§  Fallback Prediction: Using rule-based approach...")
                success_probability = issue['confidence'] * 0.8
            
            print(f"      ğŸ“Š Success Probability: {success_probability:.1%}")
            
            # Simuliere Anwendung des Fixes
            if success_probability > 0.8:
                print("      âœ… Fix applied successfully!")
                fixes_successful += 1
                
                # Simuliere Fix-Details
                if issue['type'] == 'undefined_function' and 'lenght' in issue['description']:
                    print("         Original: return data.lenght;")
                    print("         Fixed:    return data.length;")
                elif issue['type'] == 'null_pointer':
                    print("         Original: total += item.price;")
                    print("         Fixed:    if (item) total += item.price;")
            else:
                print("      âŒ Fix confidence too low, manual intervention required")
        else:
            print(f"\n   â­ï¸  Skipping {issue['type']} (confidence {issue['confidence']:.1%} < threshold)")
    
    # 7. Server Health Validation
    print("\nğŸ©º Phase 4: Server Health Validation")
    print("-" * 40)
    
    print("   Monitoring server health after fixes...")
    await asyncio.sleep(2)  # Simuliere Monitoring-Zeit
    
    health_improvements = [
        {"metric": "Response Time", "before": "2500ms", "after": "150ms", "improved": True},
        {"metric": "Error Rate", "before": "15%", "after": "2%", "improved": True},
        {"metric": "Uptime", "before": "85%", "after": "99%", "improved": True}
    ]
    
    for improvement in health_improvements:
        status = "âœ…" if improvement['improved'] else "âŒ"
        print(f"   {status} {improvement['metric']}: {improvement['before']} â†’ {improvement['after']}")
    
    # 8. Final Results Summary
    print("\nğŸ“Š DEMO RESULTS SUMMARY")
    print("=" * 60)
    
    results = {
        "servers_monitored": len(simulated_servers),
        "files_analyzed": 2,
        "issues_detected": len(detected_issues),
        "fixes_attempted": fixes_attempted,
        "fixes_successful": fixes_successful,
        "fix_success_rate": (fixes_successful / fixes_attempted * 100) if fixes_attempted > 0 else 0,
        "ai_system_active": ai_system is not None,
        "health_improvements": len([h for h in health_improvements if h['improved']])
    }
    
    print(f"ğŸ–¥ï¸  MCP Servers Monitored: {results['servers_monitored']}")
    print(f"ğŸ“ Files Analyzed: {results['files_analyzed']}")
    print(f"ğŸš¨ Code Issues Detected: {results['issues_detected']}")
    print(f"ğŸ”§ Fixes Attempted: {results['fixes_attempted']}")
    print(f"âœ… Fixes Successful: {results['fixes_successful']}")
    print(f"ğŸ¯ Fix Success Rate: {results['fix_success_rate']:.1f}%")
    print(f"ğŸ§  AI System Active: {'Yes' if results['ai_system_active'] else 'No (Fallback mode)'}")
    print(f"ğŸ“ˆ Health Improvements: {results['health_improvements']}/3 metrics improved")
    
    # 9. Next Steps Information
    print(f"\nğŸš€ NEXT STEPS")
    print("-" * 60)
    print("FÃ¼r Produktive Nutzung:")
    print("1. Starte echte MCP Server fÃ¼r Discovery")
    print("2. Konfiguriere Log-Sammlung von MCP Servern")
    print("3. Trainiere ML-Modelle mit echten Fix-Daten")
    print("4. Aktiviere kontinuierliches Monitoring")
    print("5. Integriere mit CI/CD Pipeline")
    
    print(f"\nğŸ“ Demo-Dateien verfÃ¼gbar in: {demo_dir}")
    print("ğŸ‰ Demo erfolgreich abgeschlossen!")

async def main():
    """Hauptfunktion fÃ¼r die Demo"""
    try:
        await run_comprehensive_demo()
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  Demo gestoppt durch Benutzer")
    except Exception as e:
        print(f"\nâŒ Fehler in der Demo: {e}")
        logger.exception("Demo error")

if __name__ == "__main__":
    asyncio.run(main())